{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nbase_url = \"https://github.com/marinaramalhete/DeepLearningAI_NLP_Specialization/raw/main/3%20-%20Natural%20Language%20Processing%20with%20Sequence%20Models/W2/Assignment_Deep_N_Grams/\"\n\nfiles = [\n    \"model.pkl.gz\", \"w2_unittest.py\",\n    \"data/shakespeare_data.txt\"\n]\n\nos.makedirs('data', exist_ok=True)\nfor file in files:\n    !wget -O \"{file}\" \"{base_url}{file}\"  -q --show-progress","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-30T10:53:34.504930Z","iopub.execute_input":"2025-07-30T10:53:34.505715Z","iopub.status.idle":"2025-07-30T10:53:35.238400Z","shell.execute_reply.started":"2025-07-30T10:53:34.505675Z","shell.execute_reply":"2025-07-30T10:53:35.236907Z"}},"outputs":[{"name":"stdout","text":"model.pkl.gz        100%[===================>]  12.14M  --.-KB/s    in 0.05s   \nw2_unittest.py      100%[===================>]  27.57K  --.-KB/s    in 0s      \ndata/shakespeare_da 100%[===================>]   5.04M  --.-KB/s    in 0.04s   \n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nimport traceback\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport numpy as np\nimport random as  rnd\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input\n\nfrom termcolor import colored\n\n# set random seed\nrnd.seed(32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T10:50:52.855424Z","iopub.execute_input":"2025-07-30T10:50:52.855746Z","iopub.status.idle":"2025-07-30T10:50:52.863061Z","shell.execute_reply.started":"2025-07-30T10:50:52.855715Z","shell.execute_reply":"2025-07-30T10:50:52.862094Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# 1 Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Load Data\nwith open(os.path.join('data', 'shakespeare_data.txt')) as f:\n    lines = [line.strip() for line in f if line.strip()]\n\nprint(f\"Number of lines: {len(lines)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T10:53:40.494901Z","iopub.execute_input":"2025-07-30T10:53:40.495244Z","iopub.status.idle":"2025-07-30T10:53:40.550922Z","shell.execute_reply.started":"2025-07-30T10:53:40.495213Z","shell.execute_reply":"2025-07-30T10:53:40.549929Z"}},"outputs":[{"name":"stdout","text":"Number of lines: 125097\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(\"\\n\".join(lines[506:514]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T10:54:11.556414Z","iopub.execute_input":"2025-07-30T10:54:11.556844Z","iopub.status.idle":"2025-07-30T10:54:11.561989Z","shell.execute_reply.started":"2025-07-30T10:54:11.556812Z","shell.execute_reply":"2025-07-30T10:54:11.560924Z"}},"outputs":[{"name":"stdout","text":"BENVOLIO\tHere were the servants of your adversary,\nAnd yours, close fighting ere I did approach:\nI drew to part them: in the instant came\nThe fiery Tybalt, with his sword prepared,\nWhich, as he breathed defiance to my ears,\nHe swung about his head and cut the winds,\nWho nothing hurt withal hiss'd him in scorn:\nWhile we were interchanging thrusts and blows,\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Create Vocab\ntext = \"\\n\".join(lines)\n\nvocab = sorted(set(text))\nvocab.insert(0, \"[UNK]\")  # For unknown characters\nvocab.insert(1, \"\")       # For padding\n\nprint(f\"{len(vocab)} unique characters\")\nprint(\" \".join(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T10:55:31.273536Z","iopub.execute_input":"2025-07-30T10:55:31.273909Z","iopub.status.idle":"2025-07-30T10:55:31.339845Z","shell.execute_reply.started":"2025-07-30T10:55:31.273880Z","shell.execute_reply":"2025-07-30T10:55:31.338883Z"}},"outputs":[{"name":"stdout","text":"82 unique characters\n[UNK]  \t \n   ! $ & ' ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ] a b c d e f g h i j k l m n o p q r s t u v w x y z |\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Concept: unicode_split (String Tensor)\nline = \"Hello world!\"\nchars = tf.strings.unicode_split(line, input_encoding='UTF-8')\nprint(chars)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T10:57:15.701912Z","iopub.execute_input":"2025-07-30T10:57:15.702266Z","iopub.status.idle":"2025-07-30T10:57:15.784326Z","shell.execute_reply.started":"2025-07-30T10:57:15.702242Z","shell.execute_reply":"2025-07-30T10:57:15.783279Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor([b'H' b'e' b'l' b'l' b'o' b' ' b'w' b'o' b'r' b'l' b'd' b'!'], shape=(12,), dtype=string)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Concept: StringLookup\nids = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)(chars)\nprint(ids) # Callable ids layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T10:59:10.107720Z","iopub.execute_input":"2025-07-30T10:59:10.108110Z","iopub.status.idle":"2025-07-30T10:59:10.134398Z","shell.execute_reply.started":"2025-07-30T10:59:10.108085Z","shell.execute_reply":"2025-07-30T10:59:10.133509Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor([34 59 66 66 69  4 77 69 72 66 58  5], shape=(12,), dtype=int64)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"1. You create a StringLookup layer with the given vocabulary and no mask token.\n2. Then you immediately call it with chars (which should be a tensor or list of strings).\n3. It returns the integer indices for each string in chars.","metadata":{}},{"cell_type":"code","source":"def line_to_tensor(line, vocab):\n    \"\"\"\n    Converts a line of text into a tensor of integer values representing characters.\n\n    Args:\n        line (str): A single line of text.\n        vocab (list): A list containing the vocabulary of unique characters.\n\n    Returns:\n        tf.Tensor(dtype=int64): A tensor containing integers (unicode values) corresponding to the characters in the `line`.\n    \"\"\"\n    chars = tf.strings.unicode_split(line, input_encoding='UTF-8')]\n    ids = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)(chars)\n\n    return ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:00:48.204684Z","iopub.execute_input":"2025-07-30T11:00:48.205086Z","iopub.status.idle":"2025-07-30T11:00:48.211159Z","shell.execute_reply.started":"2025-07-30T11:00:48.205058Z","shell.execute_reply":"2025-07-30T11:00:48.210004Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Concept: reduce_join\nchars_from_ids = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True, mask_token=None)\nline = tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\nprint(line)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:07:53.347500Z","iopub.execute_input":"2025-07-30T11:07:53.347884Z","iopub.status.idle":"2025-07-30T11:07:53.364452Z","shell.execute_reply.started":"2025-07-30T11:07:53.347855Z","shell.execute_reply":"2025-07-30T11:07:53.363514Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(b'Hello world!', shape=(), dtype=string)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def text_from_ids(ids, vocab):\n    \"\"\"\n    Converts a tensor of integer values into human-readable text.\n\n    Args:\n        ids (tf.Tensor): A tensor containing integer values (unicode IDs).\n        vocab (list): A list containing the vocabulary of unique characters.\n\n    Returns:\n        str: A string containing the characters in human-readable format.\n    \"\"\"\n    chars_from_ids = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True, mask_token=None)\n    line = tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n    \n    return line","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:02:49.075203Z","iopub.execute_input":"2025-07-30T11:02:49.075565Z","iopub.status.idle":"2025-07-30T11:02:49.081735Z","shell.execute_reply.started":"2025-07-30T11:02:49.075540Z","shell.execute_reply":"2025-07-30T11:02:49.080860Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Train Eval split\ntrain_lines, eval_lines = lines[:-1000], lines[-1000:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:09:26.329196Z","iopub.execute_input":"2025-07-30T11:09:26.329527Z","iopub.status.idle":"2025-07-30T11:09:26.336837Z","shell.execute_reply.started":"2025-07-30T11:09:26.329505Z","shell.execute_reply":"2025-07-30T11:09:26.335920Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Concept: from_tensor_slices\nall_ids = line_to_tensor(\"\\n\".join([\"Hello world!\", \"Generative AI\"]), vocab)\nids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n\nprint([id for id in ids_dataset.take(5)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:16:48.336965Z","iopub.execute_input":"2025-07-30T11:16:48.337285Z","iopub.status.idle":"2025-07-30T11:16:48.364244Z","shell.execute_reply.started":"2025-07-30T11:16:48.337260Z","shell.execute_reply":"2025-07-30T11:16:48.363456Z"}},"outputs":[{"name":"stdout","text":"[<tf.Tensor: shape=(), dtype=int64, numpy=34>, <tf.Tensor: shape=(), dtype=int64, numpy=59>, <tf.Tensor: shape=(), dtype=int64, numpy=66>, <tf.Tensor: shape=(), dtype=int64, numpy=66>, <tf.Tensor: shape=(), dtype=int64, numpy=69>]\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Concept: batch\nseq_length = 10\ndata_generator = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n\nprint([seq for seq in data_generator.take(5)]) # we only have 2 seqs\nprint([text_from_ids(seq, vocab).numpy() for seq in data_generator.take(5)]) # we only have 2 seqs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:19:28.693131Z","iopub.execute_input":"2025-07-30T11:19:28.693813Z","iopub.status.idle":"2025-07-30T11:19:28.724837Z","shell.execute_reply.started":"2025-07-30T11:19:28.693784Z","shell.execute_reply":"2025-07-30T11:19:28.723799Z"}},"outputs":[{"name":"stdout","text":"[<tf.Tensor: shape=(11,), dtype=int64, numpy=array([34, 59, 66, 66, 69,  4, 77, 69, 72, 66, 58])>, <tf.Tensor: shape=(11,), dtype=int64, numpy=array([ 5,  3, 33, 59, 68, 59, 72, 55, 74, 63, 76])>]\n[b'Hello world', b'!\\nGenerativ']\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"def split_input_target(sequence):\n    \"\"\"\n    Splits the input sequence into two sequences, where one is shifted by one position.\n\n    Args:\n        sequence (tf.Tensor or list): A list of characters or a tensor.\n\n    Returns:\n        tf.Tensor, tf.Tensor: Two tensors representing the input and output sequences for the model.\n    \"\"\"\n    input_text = sequence[:-1]\n    target_text = sequence[1:]\n\n    return input_text, target_text\n\nsplit_input_target(list(\"Tensorflow\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:20:26.024540Z","iopub.execute_input":"2025-07-30T11:20:26.024891Z","iopub.status.idle":"2025-07-30T11:20:26.033822Z","shell.execute_reply.started":"2025-07-30T11:20:26.024857Z","shell.execute_reply":"2025-07-30T11:20:26.032947Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## Create Batch Dataset","metadata":{}},{"cell_type":"code","source":"def create_batch_dataset(lines, vocab, seq_length=100, batch_size=64):\n    \"\"\"\n    Creates a batch dataset from a list of text lines.\n\n    Args:\n        lines (list): A list of strings with the input data, one line per row.\n        vocab (list): A list containing the vocabulary.\n        seq_length (int): The desired length of each sample.\n        batch_size (int): The batch size.\n\n    Returns:\n        tf.data.Dataset: A batch dataset generator.\n    \"\"\"\n        # Buffer size to shuffle the dataset\n        # TF data is designed to work with possibly infinite sequences.\n        # So it doesn't attempt to shuffle the entire sequence in memory. \n        # Instead, it maintains a buffer in which it shuffles elements.\n    BUFFER_SIZE = 10000\n    \n        # For simplicity, just join all lines into a single line\n    single_line_data  = \"\\n\".join(lines)\n    \n        # Convert your data into a tensor using the given vocab\n    all_ids = line_to_tensor(single_line_data, vocab)\n        # Create a TensorFlow dataset from the data tensor\n    ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n        # Create a batch dataset\n    data_generator = ids_dataset.batch(seq_length + 1, drop_remainder=True) \n        # Map each input sample using the split_input_target function\n    dataset_xy = data_generator.map(split_input_target)\n    \n        # Assemble the final dataset with shuffling, batching, and prefetching\n    dataset = (\n        dataset_xy\n        .shuffle(BUFFER_SIZE)\n        .batch(batch_size, drop_remainder=True)\n        .prefetch(tf.data.experimental.AUTOTUNE)\n    )\n    \n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:29:08.089339Z","iopub.execute_input":"2025-07-30T11:29:08.090060Z","iopub.status.idle":"2025-07-30T11:29:08.096422Z","shell.execute_reply.started":"2025-07-30T11:29:08.090031Z","shell.execute_reply":"2025-07-30T11:29:08.095494Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"dataset = create_batch_dataset(train_lines, vocab, seq_length=100, batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T11:29:08.539891Z","iopub.execute_input":"2025-07-30T11:29:08.540172Z","iopub.status.idle":"2025-07-30T11:29:10.559792Z","shell.execute_reply.started":"2025-07-30T11:29:08.540152Z","shell.execute_reply":"2025-07-30T11:29:10.558918Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"# 2. GRU Language Model\n\n- `tf.keras.layers.Embedding(input_dim, output_dim)`: Initializes the embedding. In this case it is the size of the vocabulary by the dimension of the model. [docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)  \n    - `Embedding(vocab_size, embedding_dim)`.\n    - `vocab_size` is the number of unique words in the given vocabulary.\n    - `embedding_dim` is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).\n</br></br>\n\n- `tf.keras.layers.GRU(units)`: Builds a traditional GRU of rnn_units with dense internal transformations. [docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) You can read the paper here: https://arxiv.org/abs/1412.3555\n    - `units`: Number of recurrent units in the layer. It must be set to `rnn_units`\n    - `return_sequences`: It specifies if the model returns a sequence of predictions. Set it to `True`\n    - `return_state`: It specifies if the model must return the last internal state along with the prediction. Set it to `True` \n</br></br>\n\n- `tf.keras.layers.Dense`: A dense layer. [docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense). You must set the following parameters:\n    - `units`: Number of units in the layer. It must be set to `vocab_size`\n    - `activation`: It must be set to `log_softmax` function as described in the next line.\n</br></br>\n\n- `tf.nn.log_softmax`: Log of the output probabilities. [docs](https://www.tensorflow.org/api_docs/python/tf/nn/log_softmax)\n    - You don't need to set any parameters, just set the activation parameter as `activation=tf.nn.log_softmax`.\n</br></br>\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}